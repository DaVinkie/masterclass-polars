{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6485b7-e0b1-441f-a6ed-08d9b6cea729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96114b3-0997-4606-9da1-8e8852f0b02b",
   "metadata": {},
   "source": [
    "So, by now I have probably been glazing you up about this Polars package. But, how good can it really be? Let us do some timings.\n",
    "\n",
    "First, let's initiallize some random data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13965301-0f8b-4deb-981b-9166fc41a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "some_ints = [random.randint(0, 1000) for _ in range(100000)]\n",
    "some_floats = [random.uniform(0.0, 1000.0) for _ in range(100000)]\n",
    "some_strs = [''.join(random.choices(ascii_letters, k=random.randint(1, 10))) for _ in range(100000)]\n",
    "some_gauss = [random.gauss(mu=50, sigma=5) for _ in range(100000)]\n",
    "some_cats = [\"Spicy\", \"Very spicy\", \"Mild\", \"Ultra Mild\", \"Bomboclat ðŸ˜®\"] * 20000\n",
    "\n",
    "data_dict = {\n",
    "    \"integers\": some_ints,\n",
    "    \"floats\": some_floats,\n",
    "    \"strings\": some_strs,\n",
    "    \"gauss\": some_gauss,\n",
    "    \"categories\": some_cats,\n",
    "}\n",
    "\n",
    "pandas_df = pd.DataFrame(data_dict)\n",
    "polars_df = pl.DataFrame(data_dict)\n",
    "\n",
    "print(\"Pandas DataFrame and description: \\n\\n\", pandas_df.head(), '\\n'*3, pandas_df.describe(), \"\\n================================\\n\")\n",
    "print(\"Polars DataFrame and description: \\n\\n \",  polars_df.head(), '\\n'*3, polars_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6aa4e0-21f5-4aa0-8778-0e95f1b07013",
   "metadata": {},
   "source": [
    "So far so good? As you can see, there is not much difference yet. At least the data itself should look the same, so we know calculations are performed similarly. Now, just from these print statements alone, we can see that Polars is a lot prettier. However, I don't really care about looks and this comparison is about performance, so let's dive a little deeper:\n",
    "\n",
    "# Exercise 1a\n",
    "Let us perform some typical DataFrame transformations: implement the following two functions and adhere to the type hints. You should be able to write some optimal code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa107ba-b53b-4f25-998c-2dabeba5318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_some_pandas_aggregations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" To be implemented: group the data over its categories and perform the following data aggregations: \n",
    "    - the minimum and maximum float values per group\n",
    "    - the average integer value per group\n",
    "    - the standard deviation of the gaussian sample\n",
    "    \"\"\"\n",
    "    df = _\n",
    "    return df\n",
    "\n",
    "def do_some_pandas_filtering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" To be implemented: filter the data set on entries that have strings that start with either a or b (and A or B)\n",
    "    \"\"\"\n",
    "    df = _\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb30829-be00-4847-90b1-8e717de371db",
   "metadata": {},
   "source": [
    "The following code shows you how to do this in Polars. Take a quick look and determine what is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a1d04-58ec-4993-8799-f391bba933d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_some_polars_aggregations(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.group_by(\"categories\").agg(\n",
    "        pl.col(\"floats\").min(),\n",
    "        pl.col(\"floats\").max(),\n",
    "        pl.col(\"integers\").mean(),\n",
    "        pl.col(\"gauss\").std(),\n",
    "    )\n",
    "\n",
    "def do_some_polars_filtering(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    return df.filter(\n",
    "        pl.col(\"strings\").str.starts_with('a') | \n",
    "        pl.col(\"strings\").str.starts_with('A') |\n",
    "        pl.col(\"strings\").str.starts_with('b') | \n",
    "        pl.col(\"strings\").str.starts_with('B')\n",
    "    )\n",
    "\n",
    "do_some_polars_aggregations(polars_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe41dc-9daf-4abb-af0f-b61d05eda8b5",
   "metadata": {},
   "source": [
    "# Exercise 1b\n",
    "Oopsie whoopsie, I made a fucky wucky. Clearly, this code is not finished yet. Inspect the *clear* error message, and fix the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc5a29-ba43-4957-aed5-dd631f1c9233",
   "metadata": {},
   "source": [
    "Now that you have written your own Polars code, you will see that the code is a little more verbose than trusty old pandas. There is also this returning pl.col() function, but more on that later. If you implemented your own code correctly, we can now run the following code for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386358ee-f294-4459-a335-aba3cf3eb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "pd_agg_time = %timeit -o do_some_pandas_aggregations(pandas_df)\n",
    "pl_agg_time = %timeit -o do_some_polars_aggregations(polars_df)\n",
    "pd_filt_time = %timeit -o do_some_pandas_filtering(pandas_df)\n",
    "pl_filt_time = %timeit -o do_some_polars_filtering(polars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec627f10-5687-419a-830d-b62ba7201fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = {\n",
    "    \"best_time\": [pd_agg_time.best, pl_agg_time.best, pd_filt_time.best, pl_filt_time.best],\n",
    "    \"avg_time\": [pd_agg_time.average, pl_agg_time.average, pd_filt_time.average, pl_filt_time.average],\n",
    "    \"worst_time\": [pd_agg_time.worst, pl_agg_time.worst, pd_filt_time.worst, pl_filt_time.worst],\n",
    "    \"function\": [\"agg\", \"agg\", \"filter\", \"filter\"],\n",
    "    \"lib\": [\"pandas\", \"polars\", \"pandas\", \"polars\"]\n",
    "}\n",
    "fig = px.bar(time_data, x='function', y='best_time', barmode='group', color='lib')\n",
    "fig.show()\n",
    "\n",
    "fig = px.bar(time_data, x='function', y='avg_time', barmode='group', color='lib')\n",
    "fig.show()\n",
    "\n",
    "fig = px.bar(time_data, x='function', y='worst_time', barmode='group', color='lib')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6eefa-acdc-4858-a3ef-08348ab4e7a6",
   "metadata": {},
   "source": [
    "Apparently, all those extra words are good for something! Thats a pretty significant speed up if you ask me. Especially when we get in to big data terratory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
